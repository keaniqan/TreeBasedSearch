Frozen

Epoch 1/30

val_macro_f1: 0.4463

Epoch 1: val_macro_f1 improved from None to 0.44630, saving model to models\xception_frozen.keras
64/64 - 80s - 1s/step - acc: 0.3897 - loss: 1.3023 - val_acc: 0.4822 - val_loss: 1.1981 - val_macro_f1: 0.4463 - learning_rate: 3.0000e-04
Epoch 2/30

val_macro_f1: 0.5037

Epoch 2: val_macro_f1 improved from 0.44630 to 0.50371, saving model to models\xception_frozen.keras
64/64 - 70s - 1s/step - acc: 0.5238 - loss: 1.1483 - val_acc: 0.5336 - val_loss: 1.1302 - val_macro_f1: 0.5037 - learning_rate: 3.0000e-04
Epoch 3/30

val_macro_f1: 0.5446

Epoch 3: val_macro_f1 improved from 0.50371 to 0.54457, saving model to models\xception_frozen.keras
64/64 - 70s - 1s/step - acc: 0.5538 - loss: 1.0813 - val_acc: 0.5692 - val_loss: 1.0567 - val_macro_f1: 0.5446 - learning_rate: 3.0000e-04
Epoch 4/30

val_macro_f1: 0.5388

Epoch 4: val_macro_f1 did not improve from 0.54457
64/64 - 69s - 1s/step - acc: 0.5956 - loss: 1.0314 - val_acc: 0.5771 - val_loss: 1.0395 - val_macro_f1: 0.5388 - learning_rate: 3.0000e-04
Epoch 5/30

val_macro_f1: 0.5586

Epoch 5: val_macro_f1 improved from 0.54457 to 0.55861, saving model to models\xception_frozen.keras
64/64 - 71s - 1s/step - acc: 0.6211 - loss: 0.9910 - val_acc: 0.5810 - val_loss: 1.0058 - val_macro_f1: 0.5586 - learning_rate: 3.0000e-04
Epoch 6/30

val_macro_f1: 0.5562

Epoch 6: val_macro_f1 did not improve from 0.55861
64/64 - 69s - 1s/step - acc: 0.6138 - loss: 0.9837 - val_acc: 0.5731 - val_loss: 0.9929 - val_macro_f1: 0.5562 - learning_rate: 3.0000e-04
Epoch 7/30

val_macro_f1: 0.5570

Epoch 7: val_macro_f1 did not improve from 0.55861
64/64 - 69s - 1s/step - acc: 0.6319 - loss: 0.9468 - val_acc: 0.5889 - val_loss: 0.9817 - val_macro_f1: 0.5570 - learning_rate: 3.0000e-04
Epoch 8/30

val_macro_f1: 0.5714

Epoch 8: val_macro_f1 improved from 0.55861 to 0.57138, saving model to models\xception_frozen.keras
64/64 - 70s - 1s/step - acc: 0.6285 - loss: 0.9497 - val_acc: 0.5771 - val_loss: 0.9683 - val_macro_f1: 0.5714 - learning_rate: 3.0000e-04
Epoch 9/30

val_macro_f1: 0.5730

Epoch 9: val_macro_f1 improved from 0.57138 to 0.57304, saving model to models\xception_frozen.keras
64/64 - 70s - 1s/step - acc: 0.6442 - loss: 0.9345 - val_acc: 0.5850 - val_loss: 0.9664 - val_macro_f1: 0.5730 - learning_rate: 3.0000e-04
Epoch 10/30

val_macro_f1: 0.5841

Epoch 10: val_macro_f1 improved from 0.57304 to 0.58413, saving model to models\xception_frozen.keras
64/64 - 70s - 1s/step - acc: 0.6590 - loss: 0.9056 - val_acc: 0.6126 - val_loss: 0.9732 - val_macro_f1: 0.5841 - learning_rate: 3.0000e-04
Epoch 11/30

val_macro_f1: 0.5711

Epoch 11: val_macro_f1 did not improve from 0.58413
64/64 - 69s - 1s/step - acc: 0.6462 - loss: 0.9138 - val_acc: 0.5929 - val_loss: 0.9453 - val_macro_f1: 0.5711 - learning_rate: 3.0000e-04
Epoch 12/30

val_macro_f1: 0.6059

Epoch 12: val_macro_f1 improved from 0.58413 to 0.60592, saving model to models\xception_frozen.keras
64/64 - 70s - 1s/step - acc: 0.6673 - loss: 0.8944 - val_acc: 0.6126 - val_loss: 0.9372 - val_macro_f1: 0.6059 - learning_rate: 3.0000e-04
Epoch 13/30

val_macro_f1: 0.5831

Epoch 13: val_macro_f1 did not improve from 0.60592
64/64 - 70s - 1s/step - acc: 0.6629 - loss: 0.8929 - val_acc: 0.5968 - val_loss: 0.9463 - val_macro_f1: 0.5831 - learning_rate: 3.0000e-04
Epoch 14/30

val_macro_f1: 0.5695

Epoch 14: val_macro_f1 did not improve from 0.60592
64/64 - 70s - 1s/step - acc: 0.6737 - loss: 0.8782 - val_acc: 0.6047 - val_loss: 0.9348 - val_macro_f1: 0.5695 - learning_rate: 3.0000e-04
Epoch 15/30

val_macro_f1: 0.5736

Epoch 15: val_macro_f1 did not improve from 0.60592
64/64 - 78s - 1s/step - acc: 0.6536 - loss: 0.8892 - val_acc: 0.5850 - val_loss: 0.9294 - val_macro_f1: 0.5736 - learning_rate: 3.0000e-04
Epoch 16/30

val_macro_f1: 0.5933

Epoch 16: val_macro_f1 did not improve from 0.60592
64/64 - 72s - 1s/step - acc: 0.6835 - loss: 0.8620 - val_acc: 0.6047 - val_loss: 0.9217 - val_macro_f1: 0.5933 - learning_rate: 3.0000e-04
Epoch 17/30

val_macro_f1: 0.6088

Epoch 17: val_macro_f1 improved from 0.60592 to 0.60876, saving model to models\xception_frozen.keras
64/64 - 73s - 1s/step - acc: 0.6703 - loss: 0.8804 - val_acc: 0.6166 - val_loss: 0.9123 - val_macro_f1: 0.6088 - learning_rate: 3.0000e-04
Epoch 18/30

val_macro_f1: 0.6033

Epoch 18: val_macro_f1 did not improve from 0.60876
64/64 - 72s - 1s/step - acc: 0.6885 - loss: 0.8544 - val_acc: 0.6087 - val_loss: 0.9182 - val_macro_f1: 0.6033 - learning_rate: 3.0000e-04
Epoch 19/30

val_macro_f1: 0.6089

Epoch 19: val_macro_f1 improved from 0.60876 to 0.60892, saving model to models\xception_frozen.keras

Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.
64/64 - 74s - 1s/step - acc: 0.6806 - loss: 0.8511 - val_acc: 0.6166 - val_loss: 0.9259 - val_macro_f1: 0.6089 - learning_rate: 3.0000e-04
Epoch 20/30

val_macro_f1: 0.6073

Epoch 20: val_macro_f1 did not improve from 0.60892
64/64 - 73s - 1s/step - acc: 0.6806 - loss: 0.8510 - val_acc: 0.6087 - val_loss: 0.9143 - val_macro_f1: 0.6073 - learning_rate: 1.5000e-04
Epoch 21/30

val_macro_f1: 0.5907

Epoch 21: val_macro_f1 did not improve from 0.60892

Epoch 21: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.
64/64 - 72s - 1s/step - acc: 0.6830 - loss: 0.8437 - val_acc: 0.6087 - val_loss: 0.9145 - val_macro_f1: 0.5907 - learning_rate: 1.5000e-04
Epoch 22/30

val_macro_f1: 0.5970

Epoch 22: val_macro_f1 did not improve from 0.60892
64/64 - 73s - 1s/step - acc: 0.7027 - loss: 0.8307 - val_acc: 0.6087 - val_loss: 0.9092 - val_macro_f1: 0.5970 - learning_rate: 7.5000e-05
Epoch 23/30

val_macro_f1: 0.6096

Epoch 23: val_macro_f1 improved from 0.60892 to 0.60965, saving model to models\xception_frozen.keras
64/64 - 74s - 1s/step - acc: 0.6894 - loss: 0.8574 - val_acc: 0.6166 - val_loss: 0.9086 - val_macro_f1: 0.6096 - learning_rate: 7.5000e-05
Epoch 24/30

val_macro_f1: 0.5934

Epoch 24: val_macro_f1 did not improve from 0.60965
64/64 - 73s - 1s/step - acc: 0.6840 - loss: 0.8400 - val_acc: 0.6047 - val_loss: 0.9112 - val_macro_f1: 0.5934 - learning_rate: 7.5000e-05
Epoch 25/30

val_macro_f1: 0.6025

Epoch 25: val_macro_f1 did not improve from 0.60965

Epoch 25: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.
64/64 - 73s - 1s/step - acc: 0.6963 - loss: 0.8409 - val_acc: 0.6166 - val_loss: 0.9117 - val_macro_f1: 0.6025 - learning_rate: 7.5000e-05
Epoch 26/30

val_macro_f1: 0.5986

Epoch 26: val_macro_f1 did not improve from 0.60965
64/64 - 76s - 1s/step - acc: 0.6914 - loss: 0.8317 - val_acc: 0.6126 - val_loss: 0.9082 - val_macro_f1: 0.5986 - learning_rate: 3.7500e-05
Epoch 27/30

val_macro_f1: 0.5986

Epoch 27: val_macro_f1 did not improve from 0.60965
64/64 - 73s - 1s/step - acc: 0.6806 - loss: 0.8415 - val_acc: 0.6126 - val_loss: 0.9073 - val_macro_f1: 0.5986 - learning_rate: 3.7500e-05
Epoch 28/30

val_macro_f1: 0.6033

Epoch 28: val_macro_f1 did not improve from 0.60965
64/64 - 72s - 1s/step - acc: 0.7022 - loss: 0.8325 - val_acc: 0.6166 - val_loss: 0.9077 - val_macro_f1: 0.6033 - learning_rate: 3.7500e-05

FineTune

Epoch 1/60

val_macro_f1: 0.6206

Epoch 1: val_macro_f1 improved from None to 0.62058, saving model to models\xception_finetuned.keras
64/64 - 123s - 2s/step - acc: 0.6909 - loss: 0.8307 - val_acc: 0.6285 - val_loss: 0.8603 - val_macro_f1: 0.6206 - learning_rate: 1.0000e-05
Epoch 2/60

val_macro_f1: 0.6505

Epoch 2: val_macro_f1 improved from 0.62058 to 0.65046, saving model to models\xception_finetuned.keras
64/64 - 111s - 2s/step - acc: 0.7214 - loss: 0.7886 - val_acc: 0.6640 - val_loss: 0.8418 - val_macro_f1: 0.6505 - learning_rate: 1.0000e-05
Epoch 3/60

val_macro_f1: 0.6458

Epoch 3: val_macro_f1 did not improve from 0.65046
64/64 - 110s - 2s/step - acc: 0.7312 - loss: 0.7572 - val_acc: 0.6561 - val_loss: 0.8364 - val_macro_f1: 0.6458 - learning_rate: 1.0000e-05
Epoch 4/60

val_macro_f1: 0.6545

Epoch 4: val_macro_f1 improved from 0.65046 to 0.65452, saving model to models\xception_finetuned.keras
64/64 - 111s - 2s/step - acc: 0.7504 - loss: 0.7195 - val_acc: 0.6680 - val_loss: 0.8272 - val_macro_f1: 0.6545 - learning_rate: 1.0000e-05
Epoch 5/60

val_macro_f1: 0.6675

Epoch 5: val_macro_f1 improved from 0.65452 to 0.66748, saving model to models\xception_finetuned.keras
64/64 - 113s - 2s/step - acc: 0.7577 - loss: 0.6953 - val_acc: 0.6719 - val_loss: 0.8276 - val_macro_f1: 0.6675 - learning_rate: 1.0000e-05
Epoch 6/60

val_macro_f1: 0.6691

Epoch 6: val_macro_f1 improved from 0.66748 to 0.66915, saving model to models\xception_finetuned.keras
64/64 - 112s - 2s/step - acc: 0.7779 - loss: 0.6791 - val_acc: 0.6680 - val_loss: 0.8204 - val_macro_f1: 0.6691 - learning_rate: 1.0000e-05
Epoch 7/60

val_macro_f1: 0.6675

Epoch 7: val_macro_f1 did not improve from 0.66915
64/64 - 112s - 2s/step - acc: 0.7877 - loss: 0.6628 - val_acc: 0.6680 - val_loss: 0.8196 - val_macro_f1: 0.6675 - learning_rate: 1.0000e-05
Epoch 8/60

val_macro_f1: 0.6692

Epoch 8: val_macro_f1 improved from 0.66915 to 0.66924, saving model to models\xception_finetuned.keras
64/64 - 113s - 2s/step - acc: 0.7990 - loss: 0.6339 - val_acc: 0.6759 - val_loss: 0.8077 - val_macro_f1: 0.6692 - learning_rate: 1.0000e-05
Epoch 9/60

val_macro_f1: 0.6823

Epoch 9: val_macro_f1 improved from 0.66924 to 0.68233, saving model to models\xception_finetuned.keras
64/64 - 116s - 2s/step - acc: 0.8015 - loss: 0.6233 - val_acc: 0.6917 - val_loss: 0.8005 - val_macro_f1: 0.6823 - learning_rate: 1.0000e-05
Epoch 10/60

val_macro_f1: 0.6742

Epoch 10: val_macro_f1 did not improve from 0.68233
64/64 - 147s - 2s/step - acc: 0.8059 - loss: 0.6104 - val_acc: 0.6759 - val_loss: 0.8020 - val_macro_f1: 0.6742 - learning_rate: 1.0000e-05
Epoch 11/60

val_macro_f1: 0.6810

Epoch 11: val_macro_f1 did not improve from 0.68233

Epoch 11: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.
64/64 - 150s - 2s/step - acc: 0.8143 - loss: 0.5974 - val_acc: 0.6877 - val_loss: 0.8035 - val_macro_f1: 0.6810 - learning_rate: 1.0000e-05
Epoch 12/60

val_macro_f1: 0.6838

Epoch 12: val_macro_f1 improved from 0.68233 to 0.68376, saving model to models\xception_finetuned.keras
64/64 - 153s - 2s/step - acc: 0.8486 - loss: 0.5630 - val_acc: 0.6877 - val_loss: 0.8134 - val_macro_f1: 0.6838 - learning_rate: 5.0000e-06
Epoch 13/60

val_macro_f1: 0.6836

Epoch 13: val_macro_f1 did not improve from 0.68376

Epoch 13: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.
64/64 - 150s - 2s/step - acc: 0.8447 - loss: 0.5519 - val_acc: 0.6877 - val_loss: 0.8161 - val_macro_f1: 0.6836 - learning_rate: 5.0000e-06
Epoch 14/60

val_macro_f1: 0.6989

Epoch 14: val_macro_f1 improved from 0.68376 to 0.69894, saving model to models\xception_finetuned.keras
64/64 - 155s - 2s/step - acc: 0.8477 - loss: 0.5547 - val_acc: 0.7036 - val_loss: 0.8054 - val_macro_f1: 0.6989 - learning_rate: 2.5000e-06
Epoch 15/60

val_macro_f1: 0.6925

Epoch 15: val_macro_f1 did not improve from 0.69894

Epoch 15: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-06.
64/64 - 116s - 2s/step - acc: 0.8413 - loss: 0.5640 - val_acc: 0.6957 - val_loss: 0.8074 - val_macro_f1: 0.6925 - learning_rate: 2.5000e-06
Epoch 16/60

val_macro_f1: 0.7016

Epoch 16: val_macro_f1 improved from 0.69894 to 0.70159, saving model to models\xception_finetuned.keras
64/64 - 116s - 2s/step - acc: 0.8560 - loss: 0.5482 - val_acc: 0.7036 - val_loss: 0.8012 - val_macro_f1: 0.7016 - learning_rate: 1.2500e-06
Epoch 17/60

val_macro_f1: 0.7045

Epoch 17: val_macro_f1 improved from 0.70159 to 0.70446, saving model to models\xception_finetuned.keras

Epoch 17: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-07.
64/64 - 113s - 2s/step - acc: 0.8624 - loss: 0.5277 - val_acc: 0.7075 - val_loss: 0.8039 - val_macro_f1: 0.7045 - learning_rate: 1.2500e-06
Epoch 18/60

val_macro_f1: 0.7045

Epoch 18: val_macro_f1 did not improve from 0.70446
64/64 - 104s - 2s/step - acc: 0.8604 - loss: 0.5294 - val_acc: 0.7075 - val_loss: 0.8044 - val_macro_f1: 0.7045 - learning_rate: 6.2500e-07
Epoch 19/60

val_macro_f1: 0.7041

Epoch 19: val_macro_f1 did not improve from 0.70446

Epoch 19: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-07.
64/64 - 104s - 2s/step - acc: 0.8600 - loss: 0.5327 - val_acc: 0.7075 - val_loss: 0.8036 - val_macro_f1: 0.7041 - learning_rate: 6.2500e-07
Epoch 20/60

val_macro_f1: 0.7041

Epoch 20: val_macro_f1 did not improve from 0.70446
64/64 - 105s - 2s/step - acc: 0.8555 - loss: 0.5277 - val_acc: 0.7075 - val_loss: 0.8044 - val_macro_f1: 0.7041 - learning_rate: 3.1250e-07
Epoch 21/60

val_macro_f1: 0.7045

Epoch 21: val_macro_f1 did not improve from 0.70446

Epoch 21: ReduceLROnPlateau reducing learning rate to 1.56249996052793e-07.
64/64 - 105s - 2s/step - acc: 0.8550 - loss: 0.5428 - val_acc: 0.7075 - val_loss: 0.8049 - val_macro_f1: 0.7045 - learning_rate: 3.1250e-07
Epoch 22/60

val_macro_f1: 0.7045

Epoch 22: val_macro_f1 did not improve from 0.70446
64/64 - 104s - 2s/step - acc: 0.8496 - loss: 0.5445 - val_acc: 0.7075 - val_loss: 0.8050 - val_macro_f1: 0.7045 - learning_rate: 1.5625e-07

Confusion matrix:
 [[66  2  3  0]
 [ 0 45  5  0]
 [ 8  8 31 20]
 [ 2  4 14 50]]

Classification report:
              precision    recall  f1-score   support

     00-none       0.87      0.93      0.90        71
    01-minor       0.76      0.90      0.83        50
 02-moderate       0.58      0.46      0.52        67
   03-severe       0.71      0.71      0.71        70

    accuracy                           0.74       258
   macro avg       0.73      0.75      0.74       258
weighted avg       0.73      0.74      0.74       258

Macro-F1: 0.7386499095050865